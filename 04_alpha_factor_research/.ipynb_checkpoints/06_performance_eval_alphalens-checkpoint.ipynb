{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating signal and noise â€“ how to use alphalens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantopian has open sourced the Python library, alphalens, for the performance analysis of predictive stock factors that integrates well with the backtesting library zipline and the portfolio performance and risk analysis library pyfolio that we will explore in the next chapter.\n",
    "alphalens facilitates the analysis of the predictive power of alpha factors concerning the:\n",
    "- Correlation of the signals with subsequent returns\n",
    "- Profitability of an equal or factor-weighted portfolio based on a (subset of) the signals\n",
    "- Turnover of factors to indicate the potential trading costs\n",
    "- Factor-performance during specific events\n",
    "- Breakdowns of the preceding by sector\n",
    "\n",
    "The analysis can be conducted using tearsheets or individual computations and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This notebook requires the `conda` environment `backtest`. Please see the [installation instructions](../installation/README.md) for running the latest Docker image or alternative ways to set up your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:09.253350Z",
     "start_time": "2021-04-15T20:13:09.251266Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:09.877141Z",
     "start_time": "2021-04-15T20:13:09.254732Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "from alphalens.performance import *\n",
    "from alphalens.plotting import *\n",
    "from alphalens.tears import *\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:09.879755Z",
     "start_time": "2021-04-15T20:13:09.877998Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating forward returns and factor quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To utilize `alpahalens`, we need to provide signals for a universe of assets like those returned by the ranks of the MeanReversion factor, and the forward returns earned by investing in an asset for a given holding period. .\n",
    "\n",
    "> This notebook uses the file `single_factor.pickle` with the results generated in the notebook `single_factor_zipline.ipynb` in this directory.\n",
    "\n",
    "We will recover the prices from the `single_factor.pickle` file as follows (`factor_data` accordingly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:10.699028Z",
     "start_time": "2021-04-15T20:13:09.880865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       open    high     low  QUANTITY        1        2  \\\n",
      "DATETIME                                                                  \n",
      "2022-02-17 09:58:00  177.16  177.16  177.11      -532   -532.0   -326.0   \n",
      "2022-02-17 09:59:00  177.14  177.18  176.96       641    641.0    109.0   \n",
      "2022-02-17 10:00:00  177.08  177.17  177.08      -282   -282.0    359.0   \n",
      "2022-02-17 10:01:00  177.20  177.23  177.20      -894   -894.0  -1176.0   \n",
      "2022-02-17 10:02:00  177.08  177.17  177.06      -415   -415.0  -1309.0   \n",
      "...                     ...     ...     ...       ...      ...      ...   \n",
      "2022-06-17 17:09:00  124.43  124.49  124.43       165    165.0  26416.0   \n",
      "2022-06-17 17:10:00  124.49  124.50  124.23    -16664 -16664.0 -16499.0   \n",
      "2022-06-17 17:11:00  124.24  124.24  124.15    -10984 -10984.0 -27648.0   \n",
      "2022-06-17 17:12:00  124.14  124.14  124.06     -6316  -6316.0 -17300.0   \n",
      "2022-06-17 17:13:00  124.07  124.15  123.98     -1055  -1055.0  -7371.0   \n",
      "\n",
      "                           3        4        5        6  ...        53  \\\n",
      "DATETIME                                                 ...             \n",
      "2022-02-17 09:58:00  -1584.0  -2042.0  -1563.0  -2312.0  ...  -26369.0   \n",
      "2022-02-17 09:59:00    315.0   -943.0  -1401.0   -922.0  ...  -27293.0   \n",
      "2022-02-17 10:00:00   -173.0     33.0  -1225.0  -1683.0  ...  -27533.0   \n",
      "2022-02-17 10:01:00   -535.0  -1067.0   -861.0  -2119.0  ...  -28542.0   \n",
      "2022-02-17 10:02:00  -1591.0   -950.0  -1482.0  -1276.0  ...  -29095.0   \n",
      "...                      ...      ...      ...      ...  ...       ...   \n",
      "2022-06-17 17:09:00  28377.0  41564.0  56466.0  59913.0  ...  110989.0   \n",
      "2022-06-17 17:10:00   9752.0  11713.0  24900.0  39802.0  ...   95367.0   \n",
      "2022-06-17 17:11:00 -27483.0  -1232.0    729.0  13916.0  ...   84864.0   \n",
      "2022-06-17 17:12:00 -33964.0 -33799.0  -7548.0  -5587.0  ...   76214.0   \n",
      "2022-06-17 17:13:00 -18355.0 -35019.0 -34854.0  -8603.0  ...   79193.0   \n",
      "\n",
      "                           54        55       56       57        58        59  \\\n",
      "DATETIME                                                                        \n",
      "2022-02-17 09:58:00  -27082.0  -25074.0 -22224.0 -22175.0  -20342.0  -19615.0   \n",
      "2022-02-17 09:59:00  -25728.0  -26441.0 -24433.0 -21583.0  -21534.0  -19701.0   \n",
      "2022-02-17 10:00:00  -27575.0  -26010.0 -26723.0 -24715.0  -21865.0  -21816.0   \n",
      "2022-02-17 10:01:00  -28427.0  -28469.0 -26904.0 -27617.0  -25609.0  -22759.0   \n",
      "2022-02-17 10:02:00  -28957.0  -28842.0 -28884.0 -27319.0  -28032.0  -26024.0   \n",
      "...                       ...       ...      ...      ...       ...       ...   \n",
      "2022-06-17 17:09:00  102833.0  100470.0  95104.0  98798.0  106997.0  107368.0   \n",
      "2022-06-17 17:10:00   94325.0   86169.0  83806.0  78440.0   82134.0   90333.0   \n",
      "2022-06-17 17:11:00   84383.0   83341.0  75185.0  72822.0   67456.0   71150.0   \n",
      "2022-06-17 17:12:00   78548.0   78067.0  77025.0  68869.0   66506.0   61140.0   \n",
      "2022-06-17 17:13:00   75159.0   77493.0  77012.0  75970.0   67814.0   65451.0   \n",
      "\n",
      "                      close       IBS   returns  \n",
      "DATETIME                                         \n",
      "2022-02-17 09:58:00  177.12  0.200000       NaN  \n",
      "2022-02-17 09:59:00  176.99  0.136364 -0.000734  \n",
      "2022-02-17 10:00:00  177.17  1.000000  0.001017  \n",
      "2022-02-17 10:01:00  177.23  1.000000  0.000339  \n",
      "2022-02-17 10:02:00  177.06  0.000000 -0.000959  \n",
      "...                     ...       ...       ...  \n",
      "2022-06-17 17:09:00  124.49  1.000000  0.000723  \n",
      "2022-06-17 17:10:00  124.24  0.037037 -0.002008  \n",
      "2022-06-17 17:11:00  124.15  0.000000 -0.000724  \n",
      "2022-06-17 17:12:00  124.06  0.000000 -0.000725  \n",
      "2022-06-17 17:13:00  124.15  1.000000  0.000725  \n",
      "\n",
      "[32962 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "performance = pd.read_csv('Hennes_Mauritz_1_min_data.csv')\n",
    "performance = performance.rename({'RATE': 'close'}, axis='columns')\n",
    "performance['returns'] = performance['close'].pct_change().dropna()\n",
    "performance = performance.set_index('DATETIME')\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:10.711470Z",
     "start_time": "2021-04-15T20:13:10.700139Z"
    }
   },
   "outputs": [],
   "source": [
    "performance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATETIME\n",
      "2022-02-17 09:58:00         NaN\n",
      "2022-02-17 09:59:00   -0.000734\n",
      "2022-02-17 10:00:00    0.001017\n",
      "2022-02-17 10:01:00    0.000339\n",
      "2022-02-17 10:02:00   -0.000959\n",
      "                         ...   \n",
      "2022-06-17 17:09:00    0.000723\n",
      "2022-06-17 17:10:00   -0.002008\n",
      "2022-06-17 17:11:00   -0.000724\n",
      "2022-06-17 17:12:00   -0.000725\n",
      "2022-06-17 17:13:00    0.000725\n",
      "Name: returns, Length: 32962, dtype: float64\n",
      "DATETIME                     \n",
      "2022-02-17 09:58:00  open          177.160000\n",
      "                     high          177.160000\n",
      "                     low           177.110000\n",
      "                     QUANTITY     -532.000000\n",
      "                     1            -532.000000\n",
      "                                     ...     \n",
      "2022-06-17 17:13:00  58          67814.000000\n",
      "                     59          65451.000000\n",
      "                     close         124.150000\n",
      "                     IBS             1.000000\n",
      "                     returns         0.000725\n",
      "Length: 2174322, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "prices = performance['returns']\n",
    "prices.index = performance.index\n",
    "factor = performance.stack()\n",
    "factor_data = factor\n",
    "\n",
    "print(prices)\n",
    "print(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:11.141932Z",
     "start_time": "2021-04-15T20:13:10.712591Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'tz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17448/1823496587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mQUANTILES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m alphalens_data = get_clean_factor_and_forward_returns(factor=factor_data,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                                       \u001b[0mprices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                       \u001b[0mperiods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHOLDING_PERIODS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\alphalens\\utils.py\u001b[0m in \u001b[0;36mget_clean_factor_and_forward_returns\u001b[1;34m(factor, prices, groupby, binning_by_group, quantiles, bins, periods, filter_zscore, groupby_labels, max_loss, zero_aware, cumulative_returns)\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0muse\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mforward\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mare\u001b[0m \u001b[0malready\u001b[0m \u001b[0mavailable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m     \"\"\"\n\u001b[1;32m--> 827\u001b[1;33m     forward_returns = compute_forward_returns(\n\u001b[0m\u001b[0;32m    828\u001b[0m         \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[0mprices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\alphalens\\utils.py\u001b[0m in \u001b[0;36mcompute_forward_returns\u001b[1;34m(factor, prices, periods, filter_zscore, cumulative_returns)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mfactor_dateindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mfactor_dateindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mprices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         raise NonMatchingTimezoneError(\"The timezone of 'factor' is not the \"\n\u001b[0;32m    265\u001b[0m                                        \u001b[1;34m\"same as the timezone of 'prices'. See \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute 'tz'"
     ]
    }
   ],
   "source": [
    "#prices = pd.concat([df.to_frame(d) for d, df in performance.close.dropna().items()],axis=1).T\n",
    "#prices.columns = [re.findall(r\"\\[(.+)\\]\", str(col))[0] for col in prices.columns]\n",
    "#prices.index = prices.index.normalize()\n",
    "#prices.info()\n",
    "HOLDING_PERIODS = (5, 10, 21, 42)\n",
    "QUANTILES = 5\n",
    "\n",
    "alphalens_data = get_clean_factor_and_forward_returns(factor=factor_data,\n",
    "                                                      prices=prices,\n",
    "                                                      periods=HOLDING_PERIODS,\n",
    "                                                      quantiles=QUANTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:11.497144Z",
     "start_time": "2021-04-15T20:13:11.142904Z"
    }
   },
   "outputs": [],
   "source": [
    "#factor_data = pd.concat([df.to_frame(d) for d, df in performance.factor_data.dropna().items()],axis=1).T\n",
    "#factor_data.columns = [re.findall(r\"\\[(.+)\\]\", str(col))[0] for col in factor_data.columns]\n",
    "#factor_data.index = factor_data.index.normalize()\n",
    "#factor_data = factor_data.stack()\n",
    "factor_data.index.names = ['date', 'asset']\n",
    "factor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:11.522234Z",
     "start_time": "2021-04-15T20:13:11.497999Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore('../data/assets.h5') as store:\n",
    "    sp500 = store['sp500/stooq'].close\n",
    "sp500 = sp500.resample('D').ffill().tz_localize('utc').filter(prices.index.get_level_values(0))\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the alphalens input data in the required format using the `get_clean_factor_and_forward_returns` utility function that also returns the signal quartiles and the forward returns for the given holding periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:16.056746Z",
     "start_time": "2021-04-15T20:13:11.523992Z"
    }
   },
   "outputs": [],
   "source": [
    "HOLDING_PERIODS = (5, 10, 21, 42)\n",
    "QUANTILES = 5\n",
    "alphalens_data = get_clean_factor_and_forward_returns(factor=factor_data,\n",
    "                                                      prices=prices,\n",
    "                                                      periods=HOLDING_PERIODS,\n",
    "                                                      quantiles=QUANTILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `alphalens_data` `DataFrame` contains the returns on an investment in the given asset on a given date for the indicated holding period, as well as the factor value, that is, the asset's `MeanReversion` ranking on that date, and the corresponding quantile value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:16.066311Z",
     "start_time": "2021-04-15T20:13:16.057777Z"
    }
   },
   "outputs": [],
   "source": [
    "alphalens_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:16.099784Z",
     "start_time": "2021-04-15T20:13:16.067643Z"
    }
   },
   "outputs": [],
   "source": [
    "alphalens_data.reset_index().head().to_csv('factor_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward returns and the signal quantiles are the basis for evaluating the predictive power of the signal. Typically, a factor should deliver markedly different returns for distinct quantiles, such as negative returns for the bottom quintile of the factor values and positive returns for the top quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Tear Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:45.642101Z",
     "start_time": "2021-04-15T20:13:16.100895Z"
    }
   },
   "outputs": [],
   "source": [
    "create_summary_tear_sheet(alphalens_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive performance by factor quantiles -  Returns Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we would like to visualize the average period return by factor quantile. We can use the built-in function mean_return_by_quantile from the performance and plot_quantile_returns_bar from the plotting modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:57.657768Z",
     "start_time": "2021-04-15T20:13:45.643275Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_return_by_q, std_err = mean_return_by_quantile(alphalens_data)\n",
    "mean_return_by_q_norm = mean_return_by_q.apply(lambda x: x.add(1).pow(1/int(x.name[:-1])).sub(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Return by Holding Period and Quintile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a bar chart that breaks down the mean of the forward returns for the four different holding periods based on the quintile of the factor signal. As you can see, the bottom quintiles yielded markedly more negative results than the top quintiles, except for the longest holding period:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:13:57.796418Z",
     "start_time": "2021-04-15T20:13:57.658565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_quantile_returns_bar(mean_return_by_q)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10D holding period provides slightly better results for the first and fourth quartiles. We would also like to see the performance over time of investments driven by each of the signal quintiles. \n",
    "\n",
    "We will calculate daily, as opposed to average returns for the 5D holding period, and alphalens will adjust the period returns to account for the mismatch between daily signals and a longer holding period (for details, see docs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:09.569230Z",
     "start_time": "2021-04-15T20:13:57.797516Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_return_by_q_daily, std_err = mean_return_by_quantile(alphalens_data, by_date=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative 5D Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting line plot shows that, for most of this three-year period, the top two quintiles significantly outperformed the bottom two quintiles. However, as suggested by the previous plot, signals by the fourth quintile produced a better performance than those by the top quintile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:09.854477Z",
     "start_time": "2021-04-15T20:14:09.570028Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cumulative_returns_by_quantile(mean_return_by_q_daily['5D'], period='5D', freq=None)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Distribution by Holding Period and Quintile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distributional plot highlights that the range of daily returns is fairly wide and, despite different means, the separation of the distributions is very limited so that, on any given day, the differences in performance between the different quintiles may be rather limited:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:10.118140Z",
     "start_time": "2021-04-15T20:14:09.855547Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_quantile_returns_violin(mean_return_by_q_daily)\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this book is about the design of alpha factors using ML models. ML is about optimizing some predictive objective, and in this section, we will introduce the key metrics used to measure the performance of an alpha factor. We will define alpha as the average return in excess of a benchmark.\n",
    "This leads to the information ratio (IR) that measures the average excess return per unit of risk taken by dividing alpha by the tracking risk. When the benchmark is the risk-free rate, the IR corresponds to the well-known Sharpe ratio, and we will highlight crucial statistical measurement issues that arise in the typical case when returns are not normally distributed. We will also explain the fundamental law of active management that breaks the IR down into a combination of forecasting skill and a strategy's ability to effectively leverage the forecasting skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5D Information Coefficient (Rolling Average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of alpha factors is the accurate directional prediction of future returns. Hence, a natural performance measure is the correlation between an alpha factor's predictions and the forward returns of the target assets. \n",
    "\n",
    "It is better to use the non-parametric Spearman rank correlation coefficient that measures how well the relationship between two variables can be described using a monotonic function, as opposed to the Pearson correlation that measures the strength of a linear relationship. \n",
    "\n",
    "We can obtain the information coefficient using alphalens, which relies on `scipy.stats.spearmanr` under the hood. \n",
    "\n",
    "The `factor_information_coefficient` function computes the period-wise correlation and plot_ic_ts creates a time-series plot with one-month moving average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:12.424345Z",
     "start_time": "2021-04-15T20:14:10.119003Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = factor_information_coefficient(alphalens_data)\n",
    "plot_ic_ts(ic[['5D']])\n",
    "plt.tight_layout()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient by Holding Period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time series plot shows extended periods with significantly positive moving-average IC. An IC of 0.05 or even 0.1 allows for significant outperformance if there are sufficient opportunities to apply this forecasting skill, as the fundamental law of active management will illustrate:\n",
    "\n",
    "A plot of the annual mean IC highlights how the factor's performance was historically uneven:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:14.680290Z",
     "start_time": "2021-04-15T20:14:12.425164Z"
    }
   },
   "outputs": [],
   "source": [
    "ic = factor_information_coefficient(alphalens_data)\n",
    "ic_by_year = ic.resample('A').mean()\n",
    "ic_by_year.index = ic_by_year.index.year\n",
    "ic_by_year.plot.bar(figsize=(14, 6))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turnover Tear Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor turnover measures how frequently the assets associated with a given quantile change, that is, how many trades are required to adjust a portfolio to the sequence of signals. More specifically, it measures the share of assets currently in a factor quantile that was not in that quantile in the last period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T20:14:18.840260Z",
     "start_time": "2021-04-15T20:14:14.681153Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_turnover_tear_sheet(alphalens_data);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.355px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
